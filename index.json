[{"authors":["LTorgo"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"408d9ab5ff8737d26cbd2b5288b85a91","permalink":"https://paobranco.github.io/author/luis-torgo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/luis-torgo/","section":"authors","summary":"","tags":null,"title":"Luis Torgo","type":"authors"},{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m an Assistant Professor at the School of Electrical Engineering and Computer Science in the University of Ottawa, Canada.\nMy main research interests are focused on Artificial Intelligence and Machine Learning with a special focus on imbalanced domains, outlier detection, anomaly detection, cost-sensitive and utility-based learning, fraud detection and cybersecurity.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://paobranco.github.io/author/paula-branco/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/paula-branco/","section":"authors","summary":"I\u0026rsquo;m an Assistant Professor at the School of Electrical Engineering and Computer Science in the University of Ottawa, Canada.\nMy main research interests are focused on Artificial Intelligence and Machine Learning with a special focus on imbalanced domains, outlier detection, anomaly detection, cost-sensitive and utility-based learning, fraud detection and cybersecurity.","tags":null,"title":"Paula Branco","type":"authors"},{"authors":null,"categories":null,"content":" LIDTA 2020 is a half day tutorial to be held at ECML/PKDD’2020. This tutorial is about Learning with Imbalanced Domains and Rare Event Detection. It targets both newcomers on the subject but also researchers/professionals with previous experience.\nMany real-world data-mining applications involve obtaining and evaluating predictive models using data sets with strongly imbalanced distributions of the target variable. Frequently, the least-common values of this target variable are associated with rare events that are highly relevant for end-users. Examples include many diverse domains, such as diagnosis of rare diseases, intrusion detection or popularity prediction in social media. Tackling the issues raised by imbalanced domains is crucial to both academia and industry.\nThis tutorial clearly describes the full pipeline for rare event detection. This includes i) the fundamentals and principles, ii) methods and evaluation, iii) rare events detection in classified data, iv) explanation, v) a case study on fraud detection in data streams and vi) open challenges.\nCheck the tutorial schedule HERE.\n","date":1589673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589673600,"objectID":"a6ab91ae525e108c5b77398701adbfac","permalink":"https://paobranco.github.io/news/lidta20tutorialecml/","publishdate":"2020-05-17T00:00:00Z","relpermalink":"/news/lidta20tutorialecml/","section":"news","summary":"Learning with Imbalanced Domains and Rare Event Detection","tags":null,"title":"LIDTA'20 - Tutorial accepted @ ECML/PKDD 2020","type":"news"},{"authors":null,"categories":null,"content":"\u0026ldquo;Rare events detection: Methods and Evaluation\u0026rdquo; September 2020 LIDTA\u0026rsquo;2020: Tutorial on Learning with Imbalanced Domains and Rare Event Detection at ECML/PKDD 2020 here\nTutorial page: LIDTA\n","date":1589673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589673600,"objectID":"8de9d3a5783cdc8e8d49f085e8f3f17e","permalink":"https://paobranco.github.io/talk/lidta20/","publishdate":"2020-05-17T00:00:00Z","relpermalink":"/talk/lidta20/","section":"talk","summary":"\u0026ldquo;Rare events detection: Methods and Evaluation\u0026rdquo; September 2020 LIDTA\u0026rsquo;2020: Tutorial on Learning with Imbalanced Domains and Rare Event Detection at ECML/PKDD 2020 here\nTutorial page: LIDTA","tags":null,"title":"Rare Events Detection: Methods and Evaluation","type":"talk"},{"authors":null,"categories":null,"content":"UBL is an R package developed for Utility-based Learning.\nUtility-based learning problems are framed within predictive analytics tasks. In utility-based learning problems the end-user provides has non uniform preferences regarding the predictive performance of the models. This means that some errors may represent severe consequences while other errors may not be that important. Also the accurate predictions may have different benefits for the user.\nUtility-based learning problems are very frequent in real-world applications. We can find them in medical applications, ecological/meteorological forecasting or in a financial. More information regarding utility-based learning problems can be found here. Some solutions for this problem can be found here, here or here.\nThe UBL package includes several approaches for dealing with problems with different costs/benefits across the target variable domain. This is a frequent issue in imbalanced domains, so in particular, the implemented approaches are also able to deal with this problem. A detailed explanation of the methods implemented in UBL package can be found here.\nClick here to see a presentation of UBL package!\nThe package is available on GitHub and on CRAN.\nThis is the first R package that integrates methods for dealing with both imbalanced classification and imbalanced regression problems. We also implemented more general methods for dealing with utility-based and cost-sensitive problems. These methods are also implemented for classification and regression tasks.\nSo far, and taking into acount only the downloads made through CRAN, the UBL package has a total of 17164 downloads! The last month daily average of UBL downloads is of 36!\nBelow you can observe the daily number of downloads of UBL since its initial release in April 26, 2016.\nThe following figure shows the cummulative number of downloads of UBL from CRAN since its initial release in April 26, 2016.\nThe package has been improving, and a new release of UBL is being prepared!\nDownload UBL and have fun!\n","date":1589673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589673600,"objectID":"3989c54aa342d99ce04aed273607794c","permalink":"https://paobranco.github.io/ubl/ubl-description/","publishdate":"2020-05-17T00:00:00Z","relpermalink":"/ubl/ubl-description/","section":"ubl","summary":"UBL is an R package developed for Utility-based Learning.","tags":null,"title":"UBL R Package - Utility-Based Learning in R","type":"ubl"},{"authors":null,"categories":null,"content":"New tenure track Assistant Professor Position at School of Electrical Engineering and Computer Science at University of Ottawa.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"313d4d86fe75ab21203d7b4500596223","permalink":"https://paobranco.github.io/news/assistant-prof-uottawa/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/news/assistant-prof-uottawa/","section":"news","summary":"Started an Assistant Professor Position at School of Electrical Engineering and Computer Science at University of Ottawa, Canada.","tags":null,"title":"New Assistant Professor Position","type":"news"},{"authors":null,"categories":null,"content":"New paper published on Discovery Science 2019: “The CURE for Class Imbalance\u0026rdquo;\nAbstract\nAddressing the class imbalance problem is critical for several real world applications. The application of pre-processing methods is a popular way of dealing with this problem. These solutions increase the rare class examples and/or decrease the normal class cases. However, these procedures typically only take into account the characteristics of each individual class. This segmented view of the data can have a negative impact. We propose a new method that uses an integrated view of the data classes to generate new examples and remove cases. ClUstered REsampling (CURE) is a method based on a holistic view of the data that uses hierarchical clustering and a new distance measure to guide the sampling procedure. Clusters generated in this way take into account the structure of the data. This enables CURE to avoid common mistakes made by other resampling methods. In particular, CURE prevents the generation of synthetic examples in dangerous regions and undersamples safe, non-borderline, regions of the majority class. We show the effectiveness of CURE in an extensive set of experiments with benchmark domains. We also show that CURE is a user-friendly method that does not require extensive fine-tuning of hyper-parameters.\n","date":1572220800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572220800,"objectID":"064953b201b1667575d0986e219f878c","permalink":"https://paobranco.github.io/news/new-paper-cure/","publishdate":"2019-10-28T00:00:00Z","relpermalink":"/news/new-paper-cure/","section":"news","summary":"New paper published on Discovery Science: “The CURE for Class Imbalance”","tags":null,"title":"New Paper on Discovery Science Conference","type":"news"},{"authors":null,"categories":null,"content":"New paper published on DSAA 2019: \u0026ldquo;A Study on the Impact of Data Characteristics in Imbalanced Regression Tasks\u0026rdquo;\nAbstract\nThe class imbalance problem has been thoroughly studied over the past two decades. More recently, the research community realized that the problem of imbalanced distributions also occurred in other tasks beyond classification. Regression problems are among these newly studied tasks where the problem of imbalanced domains also poses important challenges. Imbalanced regression problems occur in a diversity of real world domains such as meteorological (predicting weather extreme values), financial (extreme stock returns forecasting) or medical (anticipate rare values). In imbalanced regression the end-user preferences are biased towards values of the target variable that are under-represented on the available data. Several pre-processing methods were proposed to address this problem. These methods change the training set to force the learner to focus on the rare cases. However, as far as we know, the relationship between the data intrinsic characteristics and the performance achieved by these methods has not yet been studied for imbalanced regression tasks. In this paper we describe a study of the impact certain data characteristics may have in the results of applying pre-processing methods to imbalanced regression problems. To achieve this goal, we define potentially interesting data characteristics of regression problems. We then conduct our study using a synthetic data repository build for this purpose. We show that all the different characteristics studied have a different behaviour that is related with the level at which the data characteristic is present and the learning algorithm used. The main contributions of our work are: i) to define interesting data characteristics for regression tasks; ii) to create the first repository of imbalanced regression tasks containing 6000 data sets with controlled data characteristics; and iii) to provide insights on the impact of intrinsic data characteristics in the results of pre-processing methods for handling imbalanced regression tasks.\n","date":1570233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570233600,"objectID":"27d435afc68e6aea59ff6d61f673364f","permalink":"https://paobranco.github.io/news/new-paper-dsaa2019/","publishdate":"2019-10-05T00:00:00Z","relpermalink":"/news/new-paper-dsaa2019/","section":"news","summary":"New paper published on DSAA: “A Study on the Impact of Data Characteristics in Imbalanced Regression Tasks”","tags":null,"title":"New Paper on DSAA 2019 Conference","type":"news"},{"authors":null,"categories":null,"content":"New paper published on Neurocomputing Journal: “Pre-processing Approaches for Imbalanced Distributions” DOI:10.1016/j.neucom.2018.11.100.\nAbstract\nImbalanced domains are an important problem frequently arising in real world predictive analytics. A significant body of research has addressed imbalanced distributions in classification tasks, where the target variable is nominal. In the context of regression tasks, where the target variable is continuous, imbalanced distributions of the target variable also raise several challenges to learning algorithms. Imbalanced domains are characterized by: (1) a higher relevance being assigned to the performance on a subset of the target variable values; and (2) these most relevant values being underrepresented on the available data set. Recently, some proposals were made to address the problem of imbalanced distributions in regression. Still, this remains a scarcely explored issue with few existing solutions. This paper describes three new approaches for tackling the problem of imbalanced distributions in regression tasks. We propose the adaptation to regression tasks of random over-sampling and introduction of Gaussian Noise, and we present a new method called WEighted Relevance-based Combination Strategy (WERCS). An extensive set of experiments provides empirical evidence of the advantage of using the proposed strategies and, in particular, the WERCS method. We analyze the impact of different data characteristics in the performance of the methods. A data repository with 15 imbalanced regression data sets is also provided to the research community.\n","date":1549756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549756800,"objectID":"1919c22c5372cf52d521aeaf732983ba","permalink":"https://paobranco.github.io/news/new-paper-neurocomputing/","publishdate":"2019-02-10T00:00:00Z","relpermalink":"/news/new-paper-neurocomputing/","section":"news","summary":"New paper published on Neurocomputing Journal: “Pre-processing Approaches for Imbalanced Distributions” DOI:10.1016/j.neucom.2018.11.100.","tags":null,"title":"New Paper in Neurocomputing Journal","type":"news"},{"authors":null,"categories":null,"content":"PostDoc at Dalhousie University under the supervision of Professor Luis Torgo.\nThe PostDoc theme is \u0026ldquo;Methods for Handling Problems with Domain-specific Utility Preference Biases\u0026rdquo;.\n","date":1547683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547683200,"objectID":"89c1d214edf972032008776b56d50d78","permalink":"https://paobranco.github.io/news/postdoc-start/","publishdate":"2019-01-17T00:00:00Z","relpermalink":"/news/postdoc-start/","section":"news","summary":"Started a PostDoctoral Fellowship at Faculty of Computer Science, Dalhousie University, Halifax, Canada.","tags":null,"title":"New PostDoctoral Fellowship","type":"news"},{"authors":null,"categories":null,"content":"In several predictive tasks the end-user attention is focused in certain regions of the domain of the target variable.\nAs opposed to standard predictive tasks where all target variable values are equally important, in these particular tasks the domain has a non-uniform importance for the end-user. In many real world domains, such as financial, meteorological or medical, we can find tasks that fit into this non-standard setting. In effect, for most practical applications we observe that there is important domain knowledge that must be accounted for when solving the corresponding predictive task.\nIn these tasks, the relevance of certain regions of the domain is associated to either high costs and/or severe consequences, or to important profits and/or benefits. Initially, the research community addressed these tasks through the development of the cost-sensitive learning theory which considers only the costs component. More recently, this theory evolved to the broader framework of utility-based mining. The utility-based learning setting allows the consideration of both costs and benefits that may derive from different domain information. Although more complex, the utility-based learning framework is also more intuitive from an end-user perspective and more thorough regarding the domain information representation.\nThe first efforts for including costs and benefits into the learning procedure were concentrated in tasks with a nominal target variable (classification tasks). Still, with time, it became clear that this learning paradigm was also applicable to regression tasks, where the target variable is continuous. In this thesis we focus on the utility-based learning problem. The youth of this broader approach, specially regarding regression tasks, results in the existence of several open issues that we tackled. In particular, we identified and addressed the following main challenges: i) development of a unifying framework for utility-based learning; ii) developmentof learning methods for optimising utility in regression tasks; and iii) proposal of new pre-processing methods for addressing the problem of learning from imbalanced domains.\nThe proposal of a unifying utility-based framework allows to better understand the characteristics of these tasks, while integrating both classification and regression problems. Moreover, using this framework we are also able to establish important connections between different predictive problems.\nThe second challenge is related with the lack of methods to address utility-based regression problems. When dealing with utility-based learning if the utility information is not incorporated into the learning procedure we are only able to obtain sub-optimal models. To solve this problem we propose and evaluate new methods that allow to maximise the utility in regression. We show that these methods are effective for different utility settings.\nThe third and final challenge is related with the particular sub-class of utility-based problems known as imbalanced domains. This is also a problem insufficiently studied in the context of regression tasks. We propose and evaluate several approaches to address this problem.\nAs a practical outcome of this work, we provide UBL, an R package for utility-based learning that integrates approaches for classification and regression tasks. The UBL package includes the proposals presented in this thesis, as well as many other approaches developed for utility-based classification, providing to the research community a tool for testing and comparing different alternative methods of addressing utility-based predictive tasks.\n","date":1537142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537142400,"objectID":"73fd52ed9b7cef2d4d326d05a6380be5","permalink":"https://paobranco.github.io/news/defense-phd/","publishdate":"2018-09-17T00:00:00Z","relpermalink":"/news/defense-phd/","section":"news","summary":"PhD defended with sucess at Department of Computer Science, Faculty of Sciences, University of Porto, Portugal.","tags":null,"title":"PhD Defense - Utility-based Predictive Analytics","type":"news"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"65b2b80c16a12af6f167d35008d544b1","permalink":"https://paobranco.github.io/publication/c7/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c7/","section":"publication","summary":"Ensemble methods are well known for providing an advantage over single models in a large range of data mining and machine learning tasks. Their benefits are commonly associated to the ability of reducing the bias and/or variance in learning tasks. Ensembles have been studied both for classification and regression tasks with uniform domain preferences. However, only for imbalanced classification these methods were thoroughly studied. In this paper we present an empirical study concerning the predictive ability of ensemble methods bagging and boosting in regression tasks, using 20 data sets with imbalanced distributions, and assuming non-uniform domain preferences. Results show that ensemble methods are capable of providing improvements in predictive ability towards under-represented values, and that this improvement influences the predictive ability of models concerning the average behaviour of the data. Results also show that the smaller data sets are prone to larger improvements in predictive accuracy and that no conclusion could be drawn when considering the percentage of rare cases alone.","tags":null,"title":"Evaluation of ensemble methods in imbalanced regression tasks","type":"publication"},{"authors":[],"categories":null,"content":" webpage\n","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"91a301e31d8e52a87bd1f3555effb389","permalink":"https://paobranco.github.io/publication/c8/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c8/","section":"publication","summary":"Imbalanced domains are an important problem that arises in predictive tasks causing a loss in the performance of the most relevant cases for the user. This problem has been intensively studied for classification problems. Recently it was recognized that imbalanced domains occur in several other contexts and for a diversity of types of tasks. This paper focus on imbalanced regression tasks. Resampling strategies are among the most successful approaches to imbalanced domains. In this work we propose variants of existing resampling strategies that are able to take into account the information regarding the neighborhood of the examples. Instead of performing sampling uniformly, our proposals bias the strategies for reinforcing some regions of the data sets. In an extensive set of experiments we provide evidence of the advantage of introducing a neighborhood bias in the resampling strategies.","tags":null,"title":"Exploring resampling with neighborhood bias on imbalanced regression problems","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"3701403d944c311c54b886d9e9a72bed","permalink":"https://paobranco.github.io/publication/c4/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c4/","section":"publication","summary":"Accounting for misclassification costs is important in many practical applications of machine learning, and cost-sensitive techniques for classification have been studied extensively. Utility-based learning provides a generalization of purely cost-based approaches that considers both costs and benefits, enabling application to domains with complex cost-benefit settings. However, there is little work on utility- or cost-based learning for regression. In this paper, we formally define the problem of utility-based regression and propose a strategy for maximizing the utility of regression models. We verify our findings in a large set of experiments that show the advantage of our proposal in a diverse set of domains, learning algorithms and cost/benefit settings.","tags":null,"title":"Learning through utility optimization in regression tasks","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"fd0a8ef30ed3e09a13c71c876258197e","permalink":"https://paobranco.github.io/publication/c5/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c5/","section":"publication","summary":"This volume contains the Proceedings of the First International Workshop on Learning with Imbalanced Domains:  Theory and Applications - LIDTA2017.  This Workshop is co-organised by the Laboratory of Artificial Intelligence and Decision Support - INESC TEC and Department of Computer Science,  Faculty of Sciences,  University of Porto,  Portugal and the Department of Computer Science, Virginia Commonwealth University, RichmondVA, USA. The Workshop is co-located with the European Conference on Machine Learning and  Principles  and  Practice  of  Knowledge  Discovery  in  Databases(ECML/PKDD)  2017 and  is  held  on  the  22nd  of  September  2017  in  the  Hotel  Aleksandar  Palace,  in  Skopje, Macedonia.","tags":null,"title":"Learning with Imbalanced Domains: Preface","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"175c1d9ae764cf94a385153122f36bac","permalink":"https://paobranco.github.io/publication/c10/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c10/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"ee9c1d08ebae786e63404e22fff16037","permalink":"https://paobranco.github.io/publication/c11/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c11/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"a7b03dd42749933d99bb2b1697bddb66","permalink":"https://paobranco.github.io/publication/c12/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c12/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"008117971a246a7a619a61d81bd00cfa","permalink":"https://paobranco.github.io/publication/c13/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c13/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"0e8fe0095e1ba566d90002a8da4ec552","permalink":"https://paobranco.github.io/publication/c14/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c14/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"d5c718b193a2e7b645460dcddbbb4a82","permalink":"https://paobranco.github.io/publication/c15/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c15/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"00375f3140c21e4b62dcfd18819dcbdb","permalink":"https://paobranco.github.io/publication/c6/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c6/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1497484800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497484800,"objectID":"8d4c86171b913e56ce97dd49c416bd23","permalink":"https://paobranco.github.io/publication/c9/","publishdate":"2017-06-15T00:00:00Z","relpermalink":"/publication/c9/","section":"publication","summary":"The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners. ","tags":null,"title":"SMOGN: a pre-processing approach for imbalanced regression","type":"publication"},{"authors":[],"categories":null,"content":"","date":1465948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1465948800,"objectID":"b9b021daf957ef9696dbfec2b130dedd","permalink":"https://paobranco.github.io/publication/c3/","publishdate":"2016-06-15T00:00:00Z","relpermalink":"/publication/c3/","section":"publication","summary":"Time series forecasting is a challenging task, wherethe non-stationary characteristics of the data portrays a hardsetting for predictive tasks. A common issue is the imbalanceddistribution of the target variable, where some intervals are veryimportant to the user but severely underrepresented. Standardregression tools focus on the average behaviour of the data.However, the objective is the opposite in many forecasting tasksinvolving time series: predicting rare values. A common solutionto forecasting tasks with imbalanced data is the use of resamplingstrategies, which operate on the learning data by changing its dis-tribution in favor of a given bias. The objective of this paper is toprovide solutions capable of significantly improving the predictiveaccuracy of rare cases in forecasting tasks using imbalanced timeseries data. We extend the application of resampling strategiesto the time series context and introduce the concept of temporaland relevance bias in the case selection process of such strategies,presenting new proposals. We evaluate the results of standardregression tools and the use of resampling strategies, with andwithout bias over 24 time series data sets from 6 different sources.Results show a significant increase in predictive accuracy of rarecases associated with the use of resampling strategies, and theuse of biased strategies further increases accuracy over the non-biased strategies.","tags":null,"title":"Resampling strategies for imbalanced time series","type":"publication"},{"authors":[],"categories":null,"content":"","date":1434326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1434326400,"objectID":"dd6f6cfb76b1ca01acad2befc3cfc8da","permalink":"https://paobranco.github.io/publication/c2/","publishdate":"2015-06-15T00:00:00Z","relpermalink":"/publication/c2/","section":"publication","summary":"Violent crime is a well known social problem affecting both the quality of life and the economical development of a society. Its prediction is therefore an important asset for law enforcement agencies, since due  to  budget  constraints,  the  optimization  of  resources  is  of  extreme importance. In this work, we tackle both aspects: prediction and optimization. We propose to predict violent crime using regression and optimize the distribution of police officers through an Integer Linear Programming formulation, taking into account the previous predictions. Although some of the optimization data are synthetic, we propose it as a possible approach for the problem. Experiments showed that Random Forest performs better among the other evaluated learners, after applying the SmoteR algorithm to cope with the rare extreme values. The most severe violent crime rates were predicted for southern states, in accordance with state reports. Accordingly, these were the states with more police officers assigned during optimization.","tags":null,"title":"Crime prediction using regression and resources optimization","type":"publication"},{"authors":[],"categories":null,"content":"","date":1371254400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1371254400,"objectID":"a651f47a2aed1ca381918c02ec31c04b","permalink":"https://paobranco.github.io/publication/c1/","publishdate":"2013-06-15T00:00:00Z","relpermalink":"/publication/c1/","section":"publication","summary":"Several real world prediction problems involve forecasting rare values of a target variable. When this variable is nominal we have a problem of class imbalance that was already studied thoroughly within machine learning. For regression tasks, where the target variable is continuous, few works exist addressing this type of problem. Still, important application areas involve forecasting rare extreme values of a continuous target variable. This paper describes a contribution to this type of tasks. Namely, we propose to address such tasks by sampling approaches. These approaches change the distribution of the given training data set to decrease the problem of imbalance between the rare target cases and the most frequent ones. We present a modification of the well-known Smote algorithm that allows its use on these regression tasks. In an extensive set of experiments we provide empirical evidence for the superiority of our proposals for these particular regression tasks. The proposed SmoteR method can be used with any existing regression algorithm turning it into a general tool for addressing problems of forecasting rare extreme values of a continuous target variable.","tags":null,"title":"SMOTE for Regression","type":"publication"}]